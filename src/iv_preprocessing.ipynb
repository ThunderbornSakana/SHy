{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aefc2ee",
   "metadata": {},
   "source": [
    "## MIMIC-IV Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65616da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ef452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_admission(path) -> dict:\n",
    "    print('parsing ADMISSIONS.csv ...')\n",
    "    admission_path = os.path.join(path, 'admissions.csv')\n",
    "    admissions = pd.read_csv(\n",
    "        admission_path,\n",
    "        usecols=['subject_id', 'hadm_id', 'admittime'],\n",
    "        converters={ 'subject_id': np.int, 'hadm_id': np.int, 'admittime': np.str }\n",
    "    )\n",
    "    all_patients = dict()\n",
    "    for i, row in admissions.iterrows():\n",
    "        pid = row['subject_id']\n",
    "        admission_id = row['hadm_id']\n",
    "        admission_time = datetime.strptime(row['admittime'], '%Y-%m-%d %H:%M:%S')\n",
    "        if pid not in all_patients:\n",
    "            all_patients[pid] = []\n",
    "        admission = all_patients[pid]\n",
    "        admission.append({\n",
    "            'admission_id': admission_id,\n",
    "            'admission_time': admission_time\n",
    "        })\n",
    "\n",
    "    patient_admission = dict()\n",
    "    for pid, admissions in all_patients.items():\n",
    "        if len(admissions) > 1:\n",
    "            patient_admission[pid] = sorted(admissions, key=lambda admission: admission['admission_time'])\n",
    "\n",
    "    return patient_admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18316c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_diagnoses(path, dump_list, patient_admission: dict) -> dict:\n",
    "    print('parsing DIAGNOSES_ICD.csv ...')\n",
    "    diagnoses_path = os.path.join(path, 'diagnoses_icd.csv')\n",
    "    diagnoses = pd.read_csv(\n",
    "        diagnoses_path,\n",
    "        usecols=['subject_id', 'hadm_id', 'icd_code'],\n",
    "        converters={ 'subject_id': np.int, 'hadm_id': np.int, 'icd_code': np.str }\n",
    "    )\n",
    "\n",
    "    def to_standard_icd9(code: str):\n",
    "        split_pos = 4 if code.startswith('E') else 3\n",
    "        icd9_code = code[:split_pos] + '.' + code[split_pos:] if len(code) > split_pos else code\n",
    "        return icd9_code\n",
    "\n",
    "    admission_codes = dict()\n",
    "    for i, row in diagnoses.iterrows():\n",
    "        pid = row['subject_id']\n",
    "        if pid in patient_admission:\n",
    "            admission_id = row['hadm_id']\n",
    "            code = row['icd_code']\n",
    "            if code == '':\n",
    "                continue\n",
    "            if code.startswith('E') or code.startswith('V') or code.startswith('0') or code.startswith('1') or code.startswith('2') or code.startswith('3') or code.startswith('4') or code.startswith('5') or code.startswith('6') or code.startswith('7') or code.startswith('8') or code.startswith('9'):\n",
    "                code = to_standard_icd9(code)\n",
    "                if code in dump_list:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "            if admission_id not in admission_codes:\n",
    "                codes = []\n",
    "                admission_codes[admission_id] = codes\n",
    "            else:\n",
    "                codes = admission_codes[admission_id]\n",
    "            codes.append(code)\n",
    "\n",
    "    return admission_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316180a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_patient_by_admission(patient_admission: dict, admission_codes: dict):\n",
    "    print('calibrating patients by admission ...')\n",
    "    del_pids = []\n",
    "    for pid, admissions in patient_admission.items():\n",
    "        for admission in admissions:\n",
    "            if admission['admission_id'] not in admission_codes:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        del_pids.append(pid)\n",
    "    for pid in del_pids:\n",
    "        admissions = patient_admission[pid]\n",
    "        for admission in admissions:\n",
    "            if admission['admission_id'] in admission_codes:\n",
    "                del admission_codes[admission['admission_id']]\n",
    "        del patient_admission[pid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0bbc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = '../data/RAW/MIMIC_IV/'\n",
    "with open(f'../data/RAW/MIMIC_IV/dump_list_icd9.pkl', 'rb') as f0:\n",
    "    dump_list_icd9 = pickle.load(f0)\n",
    "patient_admission = parse_admission(raw_path)\n",
    "admission_codes = parse_diagnoses(raw_path, dump_list_icd9, patient_admission)\n",
    "calibrate_patient_by_admission(patient_admission, admission_codes)\n",
    "print('There are %d valid patients' % len(patient_admission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b66db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/MIMIC_IV/patient_admission.pkl', 'wb') as f155:\n",
    "    pickle.dump(patient_admission, f155)\n",
    "\n",
    "with open('../data/MIMIC_IV/admission_codes.pkl', 'wb') as f156:\n",
    "    pickle.dump(admission_codes, f156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0552b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_admission_num = 0\n",
    "for pid, admissions in patient_admission.items():\n",
    "    if len(admissions) > max_admission_num:\n",
    "        max_admission_num = len(admissions)\n",
    "max_code_num_in_a_visit = 0\n",
    "for admission_id, codes in admission_codes.items():\n",
    "    if len(codes) > max_code_num_in_a_visit:\n",
    "        max_code_num_in_a_visit = len(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d207ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_code(admission_codes: dict) -> (dict, dict):\n",
    "    print('encoding code ...')\n",
    "    code_map = dict()\n",
    "    for i, (admission_id, codes) in enumerate(admission_codes.items()):\n",
    "        for code in codes:\n",
    "            if code not in code_map:\n",
    "                code_map[code] = len(code_map) + 1\n",
    "\n",
    "    admission_codes_encoded = {\n",
    "        admission_id: [code_map[code] for code in codes]\n",
    "        for admission_id, codes in admission_codes.items()\n",
    "    }\n",
    "    return admission_codes_encoded, code_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_time_duration(patient_admission: dict) -> dict:\n",
    "    print('encoding time duration ...')\n",
    "    patient_time_duration_encoded = dict()\n",
    "    for pid, admissions in patient_admission.items():\n",
    "        duration = [0]\n",
    "        for i in range(1, len(admissions)):\n",
    "            days = (admissions[i]['admission_time'] - admissions[i - 1]['admission_time']).days\n",
    "            duration.append(days)\n",
    "        patient_time_duration_encoded[pid] = duration\n",
    "    return patient_time_duration_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f63c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_patients(patient_admission: dict, admission_codes: dict, code_map: dict, seed=6669) -> (np.ndarray, np.ndarray):\n",
    "    print('splitting train, valid, and test pids')\n",
    "    np.random.seed(seed)\n",
    "    common_pids = set()\n",
    "    for i, code in enumerate(code_map):\n",
    "        print('\\r\\t%.2f%%' % ((i + 1) * 100 / len(code_map)), end='')\n",
    "        for pid, admissions in patient_admission.items():\n",
    "            for admission in admissions:\n",
    "                codes = admission_codes[admission['admission_id']]\n",
    "                if code in codes:\n",
    "                    common_pids.add(pid)\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "    print('\\r\\t100%')\n",
    "    max_admission_num = 0\n",
    "    pid_max_admission_num = 0\n",
    "    for pid, admissions in patient_admission.items():\n",
    "        if len(admissions) > max_admission_num:\n",
    "            max_admission_num = len(admissions)\n",
    "            pid_max_admission_num = pid\n",
    "    common_pids.add(pid_max_admission_num)\n",
    "    remaining_pids = np.array(list(set(patient_admission.keys()).difference(common_pids)))\n",
    "    np.random.shuffle(remaining_pids)\n",
    "\n",
    "    train_num = 40725\n",
    "    train_pids = np.array(list(common_pids.union(set(remaining_pids[:(train_num - len(common_pids))].tolist()))))\n",
    "    test_pids = remaining_pids[(train_num - len(common_pids)):]\n",
    "    return train_pids, test_pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4837ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_codes_encoded, code_map = encode_code(admission_codes)\n",
    "patient_time_duration_encoded = encode_time_duration(patient_admission)\n",
    "\n",
    "code_num = len(code_map)\n",
    "\n",
    "train_pids, test_pids = split_patients(\n",
    "    patient_admission=patient_admission,\n",
    "    admission_codes=admission_codes,\n",
    "    code_map=code_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb50a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/MIMIC_IV/code_map.pkl', 'wb') as f13:\n",
    "    pickle.dump(code_map, f13)\n",
    "\n",
    "with open('../data/MIMIC_IV/admission_codes_encoded.pkl', 'wb') as f157:\n",
    "    pickle.dump(admission_codes_encoded, f157)\n",
    "\n",
    "with open('../data/MIMIC_IV/patient_time_duration_encoded.pkl', 'wb') as f158:\n",
    "    pickle.dump(patient_time_duration_encoded, f158)\n",
    "\n",
    "with open('../data/MIMIC_IV/train_pids.npy', 'wb') as f258:\n",
    "    np.save(f258, train_pids)\n",
    "\n",
    "with open('../data/MIMIC_IV/test_pids.npy', 'wb') as f259:\n",
    "    np.save(f259, test_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb04877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_code_xy(pids: np.ndarray,\n",
    "                  patient_admission: dict,\n",
    "                  admission_codes_encoded: dict,\n",
    "                  max_admission_num: int,\n",
    "                  code_num: int,\n",
    "                  max_code_num_in_a_visit: int) -> (np.ndarray, np.ndarray, np.ndarray):\n",
    "    print('building train/test codes features and labels ...')\n",
    "    n = len(pids)\n",
    "    x = np.zeros((n, max_admission_num, max_code_num_in_a_visit), dtype=int)\n",
    "    y = np.zeros((n, code_num), dtype=int)\n",
    "    lens = np.zeros((n, ), dtype=int)\n",
    "    for i, pid in enumerate(pids):\n",
    "        print('\\r\\t%d / %d' % (i + 1, len(pids)), end='')\n",
    "        admissions = patient_admission[pid]\n",
    "        for k, admission in enumerate(admissions[:-1]):\n",
    "            codes = admission_codes_encoded[admission['admission_id']]\n",
    "            x[i][k][:len(codes)] = codes\n",
    "        codes = np.array(admission_codes_encoded[admissions[-1]['admission_id']]) - 1\n",
    "        y[i][codes] = 1\n",
    "        lens[i] = len(admissions) - 1\n",
    "    print('\\r\\t%d / %d' % (len(pids), len(pids)))\n",
    "    return x, y, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f56fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_time_duration_xy(pids: np.ndarray,\n",
    "                           patient_time_duration_encoded: dict,\n",
    "                           max_admission_num: int) -> (np.ndarray, np.ndarray):\n",
    "    print('building train/valid/test time duration features and labels ...')\n",
    "    n = len(pids)\n",
    "    x = np.zeros((n, max_admission_num))\n",
    "    y = np.zeros((n, ))\n",
    "    for i, pid in enumerate(pids):\n",
    "        print('\\r\\t%d / %d' % (i + 1, len(pids)), end='')\n",
    "        duration = patient_time_duration_encoded[pid]\n",
    "        x[i][:len(duration) - 1] = duration[:-1]\n",
    "        y[i] = duration[-1]\n",
    "    print('\\r\\t%d / %d' % (len(pids), len(pids)))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7814d87e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_codes_x, train_codes_y, train_visit_lens = build_code_xy(train_pids, patient_admission, admission_codes_encoded, max_admission_num, code_num, max_code_num_in_a_visit)\n",
    "test_codes_x, test_codes_y, test_visit_lens = build_code_xy(test_pids, patient_admission, admission_codes_encoded, max_admission_num, code_num, max_code_num_in_a_visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d37b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/MIMIC_IV/train_codes_y.npy', 'wb') as f2:\n",
    "    np.save(f2, train_codes_y)\n",
    "\n",
    "with open('../data/MIMIC_IV/train_visit_lens.npy', 'wb') as f3:\n",
    "    np.save(f3, train_visit_lens)\n",
    "\n",
    "with open('../data/MIMIC_IV/test_codes_y.npy', 'wb') as f5:\n",
    "    np.save(f5, test_codes_y)\n",
    "\n",
    "with open('../data/MIMIC_IV/test_visit_lens.npy', 'wb') as f6:\n",
    "    np.save(f6, test_visit_lens)\n",
    "    \n",
    "with open('../data/MIMIC_IV/train_codes_x.npy', 'wb') as f8:\n",
    "    np.save(f8, train_codes_x)\n",
    "\n",
    "with open('../data/MIMIC_IV/test_codes_x.npy', 'wb') as f9:\n",
    "    np.save(f9, test_codes_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_icd9_range(range_: str) -> (str, str, int, int):\n",
    "    ranges = range_.lstrip().split('-')\n",
    "    if ranges[0][0] == 'V':\n",
    "        prefix = 'V'\n",
    "        format_ = '%02d'\n",
    "        start, end = int(ranges[0][1:]), int(ranges[1][1:])\n",
    "    elif ranges[0][0] == 'E':\n",
    "        prefix = 'E'\n",
    "        format_ = '%03d'\n",
    "        start, end = int(ranges[0][1:]), int(ranges[1][1:])\n",
    "    else:\n",
    "        prefix = ''\n",
    "        format_ = '%03d'\n",
    "        if len(ranges) == 1:\n",
    "            start = int(ranges[0])\n",
    "            end = start + 1\n",
    "        else:\n",
    "            start, end = int(ranges[0]), int(ranges[1])\n",
    "    return prefix, format_, start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code_levels(path, code_map: dict) -> np.ndarray:\n",
    "    print('generating code levels ...')\n",
    "    three_level_code_set = set(code.split('.')[0] for code in code_map)\n",
    "    icd9_path = os.path.join(path, 'icd9.txt')\n",
    "    icd9_range = list(open(icd9_path, 'r', encoding='utf-8').readlines())\n",
    "    three_level_dict = dict()\n",
    "    level1, level2, level3 = (1, 1, 1)\n",
    "    level1_can_add = False\n",
    "    for range_ in icd9_range:\n",
    "        range_ = range_.rstrip()\n",
    "        if range_[0] == ' ':\n",
    "            prefix, format_, start, end = parse_icd9_range(range_)\n",
    "            level2_cannot_add = True\n",
    "            for i in range(start, end + 1):\n",
    "                code = prefix + format_ % i\n",
    "                if code in three_level_code_set:\n",
    "                    three_level_dict[code] = [level1, level2, level3]\n",
    "                    level3 += 1\n",
    "                    level1_can_add = True\n",
    "                    level2_cannot_add = False\n",
    "            if not level2_cannot_add:\n",
    "                level2 += 1\n",
    "        else:\n",
    "            if level1_can_add:\n",
    "                level1 += 1\n",
    "                level1_can_add = False\n",
    "\n",
    "    level4 = 1\n",
    "    code_level = dict()\n",
    "    for code in code_map:\n",
    "        three_level_code = code.split('.')[0]\n",
    "        if three_level_code in three_level_dict:\n",
    "            three_level = three_level_dict[three_level_code]\n",
    "            code_level[code] = three_level + [level4]\n",
    "            level4 += 1\n",
    "        else:\n",
    "            code_level[code] = [0, 0, 0, 0]\n",
    "\n",
    "    code_level_matrix = np.zeros((len(code_map) + 1, 4), dtype=int)\n",
    "    for code, cid in code_map.items():\n",
    "        code_level_matrix[cid] = code_level[code]\n",
    "\n",
    "    return code_level_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17891256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patient_code_adjacent(code_x: np.ndarray, code_num: int) -> np.ndarray:\n",
    "    print('generating patient code adjacent matrix ...')\n",
    "    result = np.zeros((len(code_x), code_num + 1), dtype=int)\n",
    "    for i, codes in enumerate(code_x):\n",
    "        adj_codes = codes[codes > 0]\n",
    "        result[i][adj_codes] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85bf654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code_code_adjacent(code_num: int, code_level_matrix: np.ndarray) -> np.ndarray:\n",
    "    print('generating code code adjacent matrix ...')\n",
    "    n = code_num + 1\n",
    "    result = np.zeros((n, n), dtype=int)\n",
    "    for i in range(1, n):\n",
    "        print('\\r\\t%d / %d' % (i, n), end='')\n",
    "        for j in range(1, n):\n",
    "            if i != j:\n",
    "                level_i = code_level_matrix[i]\n",
    "                level_j = code_level_matrix[j]\n",
    "                same_level = 4\n",
    "                while same_level > 0:\n",
    "                    level = same_level - 1\n",
    "                    if level_i[level] == level_j[level]:\n",
    "                        break\n",
    "                    same_level -= 1\n",
    "                result[i, j] = same_level + 1\n",
    "    print('\\r\\t%d / %d' % (n, n))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944242ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occur(pids: np.ndarray,\n",
    "             patient_admission: dict,\n",
    "             admission_codes_encoded: dict,\n",
    "             code_num: int) -> (np.ndarray, np.ndarray, np.ndarray):\n",
    "    print('calculating co-occurrence ...')\n",
    "    x = np.zeros((code_num + 1, code_num + 1), dtype=float)\n",
    "    for i, pid in enumerate(pids):\n",
    "        print('\\r\\t%d / %d' % (i + 1, len(pids)), end='')\n",
    "        admissions = patient_admission[pid]\n",
    "        for k, admission in enumerate(admissions[:-1]):\n",
    "            codes = admission_codes_encoded[admission['admission_id']]\n",
    "            for m in range(len(codes) - 1):\n",
    "                for n in range(m + 1, len(codes)):\n",
    "                    c_i, c_j = codes[m], codes[n]\n",
    "                    x[c_i, c_j] = 1\n",
    "                    x[c_j, c_i] = 1\n",
    "    print('\\r\\t%d / %d' % (len(pids), len(pids)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = len(train_pids)\n",
    "train_patient_ids = np.arange(0, l1)\n",
    "l2 = l1 + 0\n",
    "l3 = l2 + len(test_pids)\n",
    "test_patient_ids = np.arange(l2, l3)\n",
    "pid_map = dict()\n",
    "for i, pid in enumerate(train_pids):\n",
    "    pid_map[pid] = train_patient_ids[i]\n",
    "for i, pid in enumerate(test_pids):\n",
    "    pid_map[pid] = test_patient_ids[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de72953",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/MIMIC_IV/pid_map.pkl', 'wb') as f133:\n",
    "    pickle.dump(pid_map, f133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/RAW/'\n",
    "code_levels = generate_code_levels(data_path, code_map)\n",
    "\n",
    "patient_code_adj = generate_patient_code_adjacent(code_x=train_codes_x, code_num=code_num)\n",
    "patient_code_adj = np.delete(patient_code_adj, 0, 1)\n",
    "with open('../data/MIMIC_IV/patient_code_adj.npy', 'wb') as f11:\n",
    "    np.save(f11, patient_code_adj)\n",
    "\n",
    "code_code_adj_t = generate_code_code_adjacent(code_level_matrix=code_levels, code_num=code_num)\n",
    "code_levels = code_levels[1:][:]\n",
    "with open('../data/MIMIC_IV/code_levels.npy', 'wb') as f10:\n",
    "    np.save(f10, code_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occur_matrix = co_occur(train_pids, patient_admission, admission_codes_encoded, code_num)\n",
    "code_code_adj = code_code_adj_t * co_occur_matrix\n",
    "code_code_adj = np.delete(code_code_adj[1:][:], 0, 1)\n",
    "with open('../data/MIMIC_IV/code_code_adj.npy', 'wb') as f12:\n",
    "    np.save(f12, code_code_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a1bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_codes_x = []\n",
    "for i in range(len(train_pids)):\n",
    "    one_patient = np.zeros((train_visit_lens[i], code_num))\n",
    "    for ii in range(train_visit_lens[i]):\n",
    "        temp = train_codes_x[i][ii]\n",
    "        temp = temp[temp > 0] - 1\n",
    "        one_patient[ii][temp] = 1\n",
    "    binary_train_codes_x.append(one_patient)\n",
    "\n",
    "with open('../data/MIMIC_IV/binary_train_codes_x.pkl', 'wb') as f134:\n",
    "    pickle.dump(binary_train_codes_x, f134)\n",
    "\n",
    "binary_test_codes_x = []\n",
    "for i in range(len(test_pids)):\n",
    "    one_patient = np.zeros((test_visit_lens[i], code_num))\n",
    "    for ii in range(test_visit_lens[i]):\n",
    "        temp = test_codes_x[i][ii]\n",
    "        temp = temp[temp > 0] - 1\n",
    "        one_patient[ii][temp] = 1\n",
    "    binary_test_codes_x.append(one_patient)\n",
    "\n",
    "with open('../data/MIMIC_IV/binary_test_codes_x.pkl', 'wb') as f135:\n",
    "    pickle.dump(binary_test_codes_x, f135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebaeb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx, idx1 = 0, 0\n",
    "for j, btcx in enumerate(binary_train_codes_x):\n",
    "    if btcx.shape[0] > maxx:\n",
    "        maxx = btcx.shape[0]\n",
    "        idx1 = j\n",
    "target = binary_train_codes_x[idx1]\n",
    "np.save(f'../data/MIMIC_IV/anchor_train.npy', target)\n",
    "\n",
    "maxx, idx2 = 0, 0\n",
    "for i, btcx in enumerate(binary_test_codes_x):\n",
    "    if btcx.shape[0] > maxx:\n",
    "        maxx = btcx.shape[0]\n",
    "        idx2 = i\n",
    "target = binary_test_codes_x[idx2]\n",
    "np.save(f'../data/MIMIC_IV/anchor_test.npy', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4898b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, btcx in enumerate(binary_train_codes_x):\n",
    "    np.save(f'../data/MIMIC_IV/binary_train_x_slices/binary_train_codes_x_{ii}.npy', btcx)\n",
    "\n",
    "for jj, btcx in enumerate(binary_test_codes_x):\n",
    "    np.save(f'../data/MIMIC_IV/binary_test_x_slices/binary_test_codes_x_{jj}.npy', btcx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea74373e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
